{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Niko\\Anaconda3\\envs\\iannwtf\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_ds, test_ds = tfds.load('mnist', split= ['train','test'], as_supervised= True)\n",
    "\n",
    "#train_ds.show_examples\n",
    "#train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many training/test images are there: There are 60.000 training images and 10.000 test images\n",
    "\n",
    "Whats the image shape: It is a monochrome image with size 28x28px. 28x28x1\n",
    "\n",
    "What range are pixel values in: 256 possible values (0-255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07CA8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07CA8>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (tf.reshape(img, ((- 1),)), target))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07CA8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07CA8>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (tf.reshape(img, ((- 1),)), target))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07CA8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07CA8>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (tf.reshape(img, ((- 1),)), target))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B3055E6048> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B3055E6048>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (tf.reshape(img, ((- 1),)), target))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B3055E6048> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B3055E6048>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (tf.reshape(img, ((- 1),)), target))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B3055E6048> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B3055E6048>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (tf.reshape(img, ((- 1),)), target))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B30552D048> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B30552D048>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B30552D048> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B30552D048>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B30552D048> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B30552D048>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B305518708> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B305518708>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B305518708> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B305518708>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B305518708> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B305518708>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07AF8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07AF8>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (tf.reshape(img, ((- 1),)), target))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07AF8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07AF8>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (tf.reshape(img, ((- 1),)), target))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07AF8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07AF8>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (tf.reshape(img, ((- 1),)), target))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07678> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07678>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (tf.reshape(img, ((- 1),)), target))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07678> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07678>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (tf.reshape(img, ((- 1),)), target))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07678> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B312C07678>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (tf.reshape(img, ((- 1),)), target))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B30FFABE58> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B30FFABE58>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B30FFABE58> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B30FFABE58>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B30FFABE58> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B30FFABE58>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B312CC15E8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B312CC15E8>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B312CC15E8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B312CC15E8>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function mnist_dataprep.<locals>.<lambda> at 0x000001B312CC15E8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function mnist_dataprep.<locals>.<lambda> at 0x000001B312CC15E8>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
      "\n",
      "Match 1:\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "def mnist_dataprep(data):\n",
    "  # cast img type to float and flatten dimensions \n",
    "  data = data.map(lambda img, target: (tf.cast(img, tf.float32), target)).map(lambda img, target: (tf.reshape(img, (-1,)), target))\n",
    "\n",
    "  # normalize values and onehot encoding\n",
    "  data = data.map(lambda img, target: ((img/128.)-1., target)).map(lambda img, target: (img, tf.one_hot(target, depth = 10)))\n",
    "\n",
    "  # cache progress in memory\n",
    "  data = data.cache()\n",
    "  \n",
    "  # shuffle, batch, prefetch\n",
    "  data = data.shuffle(1000).batch(32).prefetch(20)\n",
    "\n",
    "  return data\n",
    "\n",
    "train_dataset = train_ds.apply(mnist_dataprep)\n",
    "test_dataset = test_ds.apply(mnist_dataprep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_units, activation_function, **kwargs):\n",
    "        super(Dense, self).__init__(**kwargs)\n",
    "        # no variables created\n",
    "        self.n_units = n_units\n",
    "        self.activation_function = activation_function\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.w = tf.Variable(tf.random.normal([input_shape[-1], self.n_units]), name='weights')\n",
    "        self.b = tf.Variable(tf.zeros([self.n_units]), name='bias')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs @ self.w + self.b\n",
    "        return self.activation_function(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, l_size):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.dense1 = tf.keras.layers.Dense(l_size, activation=tf.nn.relu)\n",
    "    self.dense2 = tf.keras.layers.Dense(l_size, activation=tf.nn.relu)\n",
    "\n",
    "    self.out = tf.keras.layers.Dense(10, activation= tf.nn.sigmoid)\n",
    "\n",
    "  @tf.function\n",
    "  def call(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    x = self.dense2(x)\n",
    "    x = self.out(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, input, target, loss_function, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = model(input)\n",
    "        loss = loss_function(target, prediction)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def test_step(model, test_data, loss_function):\n",
    "    test_accuracy_aggregator = []\n",
    "    test_loss_aggregator = []\n",
    "\n",
    "    for (input, target) in test_data:\n",
    "        prediction = model(input)\n",
    "        sample_test_loss = loss_function(target, prediction)\n",
    "        sample_test_accuracy = np.mean(np.argmax(target, axis = 1) == np.argmax(prediction, axis=1))\n",
    "        test_loss_aggregator.append(sample_test_loss.numpy())\n",
    "        test_accuracy_aggregator.append(np.mean(sample_test_accuracy))\n",
    "\n",
    "    test_loss = tf.reduce_mean(test_loss_aggregator)\n",
    "    test_accuracy = tf.reduce_mean(test_accuracy_aggregator)\n",
    "\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(epochs,lr, momentum, l_size):    \n",
    "    # Initialize the model\n",
    "    model = MyModel(l_size)\n",
    "    cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.SGD(lr, momentum)\n",
    "    \n",
    "    # visualization lists\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    # testing on test data before begin\n",
    "    test_loss, test_accuracy = test_step(model, test_dataset, cross_entropy_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # testing on test data before begin\n",
    "    train_loss, _ = test_step(model, train_dataset, cross_entropy_loss)\n",
    "    train_losses.append(test_loss)\n",
    "\n",
    "    # train for epochs\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch: {str(epoch)} starting with accuracy {test_accuracies[-1]}')  \n",
    "\n",
    "        epoch_loss_agg = []\n",
    "        for input, target in train_dataset:\n",
    "            train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
    "            epoch_loss_agg.append(train_loss)\n",
    "\n",
    "        train_losses.append(tf.reduce_mean(epoch_loss_agg))\n",
    "\n",
    "        test_loss, test_accuracy = test_step(model, test_dataset, cross_entropy_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "    \n",
    "    #Plotting the measurment data\n",
    "    line1, = plt.plot(train_losses, 'b-', label='training loss')\n",
    "    line2, = plt.plot(test_losses, 'r-', label='test loss')\n",
    "    line3, = plt.plot(test_accuracies, 'g-', label='test accuracies')\n",
    "\n",
    "    plt.title('Network Performance')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend(handles=[line1,line2,line3])\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 starting with accuracy 0.093125\n",
      "Epoch: 1 starting with accuracy 0.6278125\n",
      "Epoch: 2 starting with accuracy 0.73375\n",
      "Epoch: 3 starting with accuracy 0.77125\n",
      "Epoch: 4 starting with accuracy 0.8025\n",
      "Epoch: 5 starting with accuracy 0.8171875\n",
      "Epoch: 6 starting with accuracy 0.8346875\n",
      "Epoch: 7 starting with accuracy 0.8440625\n",
      "Epoch: 8 starting with accuracy 0.8484375\n",
      "Epoch: 9 starting with accuracy 0.8590625\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 0.01\n",
    "l_size = 265\n",
    "momentum = 0.03\n",
    "\n",
    "#Limit input data\n",
    "train_dataset = train_dataset.take(100)\n",
    "test_dataset = test_dataset.take(100)\n",
    "\n",
    "process(epochs,lr,momentum,l_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 starting with accuracy 0.114375\n",
      "Epoch: 1 starting with accuracy 0.701875\n",
      "Epoch: 2 starting with accuracy 0.8009375\n",
      "Epoch: 3 starting with accuracy 0.7815625\n",
      "Epoch: 4 starting with accuracy 0.86625\n",
      "Epoch: 5 starting with accuracy 0.850625\n",
      "Epoch: 6 starting with accuracy 0.87625\n",
      "Epoch: 7 starting with accuracy 0.8840625\n",
      "Epoch: 8 starting with accuracy 0.8834375\n",
      "Epoch: 9 starting with accuracy 0.8778125\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 0.03\n",
    "l_size = 265\n",
    "momentum = 0.03\n",
    "\n",
    "#Limit input data\n",
    "train_dataset = train_dataset.take(100)\n",
    "test_dataset = test_dataset.take(100)\n",
    "\n",
    "process(epochs,lr,momentum,l_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 starting with accuracy 0.1221875\n",
      "Epoch: 1 starting with accuracy 0.5046875\n",
      "Epoch: 2 starting with accuracy 0.644375\n",
      "Epoch: 3 starting with accuracy 0.70125\n",
      "Epoch: 4 starting with accuracy 0.7271875\n",
      "Epoch: 5 starting with accuracy 0.760625\n",
      "Epoch: 6 starting with accuracy 0.753125\n",
      "Epoch: 7 starting with accuracy 0.7653125\n",
      "Epoch: 8 starting with accuracy 0.781875\n",
      "Epoch: 9 starting with accuracy 0.794375\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 0.01\n",
    "l_size = 100\n",
    "momentum = 0.03\n",
    "\n",
    "#Limit input data\n",
    "train_dataset = train_dataset.take(100)\n",
    "test_dataset = test_dataset.take(100)\n",
    "\n",
    "process(epochs,lr,momentum,l_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 starting with accuracy 0.1175\n",
      "Epoch: 1 starting with accuracy 0.6046875\n",
      "Epoch: 2 starting with accuracy 0.7265625\n",
      "Epoch: 3 starting with accuracy 0.778125\n",
      "Epoch: 4 starting with accuracy 0.79375\n",
      "Epoch: 5 starting with accuracy 0.813125\n",
      "Epoch: 6 starting with accuracy 0.8334375\n",
      "Epoch: 7 starting with accuracy 0.8378125\n",
      "Epoch: 8 starting with accuracy 0.8465625\n",
      "Epoch: 9 starting with accuracy 0.836875\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 0.01\n",
    "l_size = 265\n",
    "momentum = 0.08\n",
    "\n",
    "#Limit input data\n",
    "train_dataset = train_dataset.take(100)\n",
    "test_dataset = test_dataset.take(100)\n",
    "\n",
    "process(epochs,lr,momentum,l_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
